<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emotion Song Player with Vinyl</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f0f0f0;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
        }
        .container {
            display: flex;
            gap: 20px;
            background-color: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        .video-container {
            width: 300px;
            height: 300px;
            border: 2px dashed red;
            overflow: hidden;
        }
        .animation-container {
            width: 300px;
            height: 300px;
        }
        .emotion-container {
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            padding-left: 20px;
        }
        h2 {
            margin: 0;
            font-size: 20px;
        }
        #emotion {
            background-color: yellow;
            padding: 5px;
            border-radius: 5px;
        }
        #dial {
            margin-top: 20px;
        }
        audio {
            margin-top: 10px;
            display: none; /* Hide audio controls since weâ€™re controlling playback */
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Camera on the left -->
        <div class="video-container">
            <video id="video" width="300" height="300" autoplay></video>
        </div>
        <!-- Vinyl animation on the right -->
        <div class="animation-container">
            <dotlottie-player src="https://lottie.host/ddf9e9b0-c94c-4805-bf11-06ef81532052/02gHsFcw1C.json" 
                              background="transparent" 
                              speed="1" 
                              style="width: 300px; height: 300px" 
                              loop 
                              autoplay>
            </dotlottie-player>
        </div>
        <div class="emotion-container">
            <h2>Detected Emotion: <span id="emotion">Waiting...</span></h2>
            <canvas id="dial" width="200" height="200"></canvas>
            <audio id="audio" controls></audio>
        </div>
    </div>

    <!-- Load required libraries -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.9.0"></script>
    <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.js"></script>
    <script src="https://unpkg.com/@dotlottie/player-component@2.7.12/dist/dotlottie-player.mjs" type="module"></script>
    <script>
        const video = document.getElementById('video');
        const audio = document.getElementById('audio');
        const emotionDisplay = document.getElementById('emotion');
        const canvas = document.getElementById('dial');
        const ctx = canvas.getContext('2d');
        let angle = 0;
        let currentEmotion = null;
        let expressionCounts = { happy: 0, sad: 0, neutral: 0, angry: 0 };

        // Map emotions to online music URLs (replace with actual links)
        const songMap = {
            'happy': 'https://www.soundhelix.com/examples/mp3/SoundHelix-Song-1.mp3',
            'sad': 'https://www.soundhelix.com/examples/mp3/SoundHelix-Song-2.mp3',
            'neutral': 'https://www.soundhelix.com/examples/mp3/SoundHelix-Song-3.mp3',
            'angry': 'https://www.soundhelix.com/examples/mp3/SoundHelix-Song-4.mp3'
        };

        // Access webcam
        navigator.mediaDevices.getUserMedia({ video: true })
            .then(stream => {
                video.srcObject = stream;
            })
            .catch(error => {
                console.error('Error accessing webcam:', error);
                alert('Please allow webcam access to use this app.');
            });

        // Load face-api.js models
        async function loadModel() {
            await faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/');
            await faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/');
            await faceapi.nets.faceExpressionNet.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/');
        }

        loadModel().then(() => {
            console.log('Models loaded');
            startDetectionCycle();
        }).catch(error => {
            console.error('Error loading models:', error);
            alert('Trouble loading the face detection models.');
        });

        // Detection cycle every 5 seconds
        function startDetectionCycle() {
            setInterval(async () => {
                expressionCounts = { happy: 0, sad: 0, neutral: 0, angry: 0 };
                let detectionsMade = 0;
                for (let i = 0; i < 5; i++) {
                    const detections = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
                        .withFaceLandmarks()
                        .withFaceExpressions();
                    if (detections && detections.expressions) {
                        const emotion = detections.expressions.asSortedArray()[0].expression;
                        expressionCounts[emotion]++;
                        detectionsMade++;
                    } else {
                        emotionDisplay.innerText = 'Please position your face in front of the camera for emotion detection.';
                    }
                    await new Promise(resolve => setTimeout(resolve, 1000)); // Wait 1 second
                }
                const dominantEmotion = getDominantEmotion();
                if (dominantEmotion && dominantEmotion !== currentEmotion) {
                    currentEmotion = dominantEmotion;
                    audio.src = songMap[dominantEmotion];
                    audio.play();
                    emotionDisplay.innerText = dominantEmotion;
                } else if (detectionsMade === 0) {
                    emotionDisplay.innerText = 'No consistent emotion detected. Please try again.';
                }
            }, 5000); // Every 5 seconds
        }

        // Find the dominant emotion
        function getDominantEmotion() {
            let maxCount = 0;
            let dominantEmotion = null;
            for (const [emotion, count] of Object.entries(expressionCounts)) {
                if (count > maxCount) {
                    maxCount = count;
                    dominantEmotion = emotion;
                }
            }
            return dominantEmotion;
        }

        // Draw spinning dial (optional visualization)
        function drawDial() {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.save();
            ctx.translate(100, 100);
            ctx.rotate(angle);
            ctx.beginPath();
            ctx.arc(0, 0, 90, 0, 2 * Math.PI);
            ctx.stroke();
            ctx.beginPath();
            ctx.moveTo(0, 0);
            ctx.lineTo(90, 0);
            ctx.stroke();
            ctx.restore();
            angle += 0.01;
            requestAnimationFrame(drawDial);
        }
        drawDial();
    </script>
</body>
</html>
